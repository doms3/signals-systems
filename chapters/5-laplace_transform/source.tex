\documentclass{article}

\usepackage{amsmath}

\begin{document}
    \section{Laplace Transform}
    The motivation for the Laplace transform comes from a desire to more easily solve differential equations. This is because the most general way to describe a linear, time independent system is that given an input function $x(t)$ the output function $y(t)$ satisfies the differential equation $$a_0y(t) + a_1y'(t) + a_2y''(t) + ... = b_0x(t) + b_1x'(t) + b_2x''(t) + ...$$ 
    The idea of the Laplace transform is that the input and output functions are viewed as a sum of functions that play very nicely with differentition. We begin with the fact that the exponential function, $e^x$ is one such function. This is because $$\frac{d}{dx} e^x = e^x$$ In a bit of mathematical jargon, when the differential operator is applied to $e^x$ since the output is again $e^x$ we say that $e^x$ is an eigenfunction of $\frac{d}{dx}$. More generally, in any case where applying an operator has the effect of "stretching" a function (multiplying it by a constant) we say that function if an eigenfunction of the operator. With this knowledge, we can find all the eigenfunctions of $\frac{d}{dx}$. We know by definition, to be an eigenfunction of $\frac{d}{dx}$ $$\frac{d}{dx}f(x) = \lambda f(x)$$ where $\lambda$ is some number we don't know yet. The symbol $\lambda$ is used as convention. The solution to this differential equation is $f(x) = ke^{\lambda x}$ and with this knowledge we have characterized all the eigenfunctions of $\frac{d}{dx}$. Soon mathematitions realized that no only do each of these eigenfunctions play nicely under differentiation, but sums and differences of these functions do as well. For example $$\frac{d}{dx} \left[ e^x + e^{2x} \right] = e^x + 2e^{2x}$$ since the differential operator simply stretches each of the constituent parts. 
    Let's relate what we've shown above to an example system. Suppose given an input $x(t)$ the output of a system $H$, $y(t) = H\left[ x(t) \right]$ satisfies $$2y'(t) + y(t) = x''(t) + 2x(t)$$
    Let us examine what the system does to an input of the form $x(t) = ke^{\lambda t}$, that is to an eigenfunction of $\frac{d}{dt}$. In this case we know the output $y(t)$ satisfies the differential equation $$2y'(t) + y(t) = \frac{d^2}{dt^2}ke^{\lambda t} + 2ke^{\lambda t} = k\lambda^2 e^{\lambda t} + 2ke^{\lambda t}$$ We may hope that since $x(t)$ is an eigenfunction of $\frac{d}{dt}$, $x(t)$ will be an eigenfunction of our system as well. This would imply that $y(t) = \alpha k e^{\lambda t}$. For this to be true, $$2\alpha k\lambda e^{\lambda t} + \alpha ke^{\lambda t} = \lambda^2 ke^{\lambda t} + 2ke^{\lambda t} \implies 2\alpha\lambda + \alpha = \lambda^2 + 2$$ which would suggest that $$\alpha = \frac{\lambda^2 + 1}{\lambda + 1}$$
    Since such an $\alpha$ does exist, we have proven exactly what we'd like to discover. The family of exponentials $f_\lambda(t) \equiv e^{\lambda t}$ are in fact eigenfunctions of the system $H$. More generally, it turns out that given any linear, time-independent system $H$, we will find that the exponential family of functions are eigenfunctions.
    This is great if the input to our system is already an eigenfunction but what about the case of a more general function $x(t)$. An important discovery was made that many functions $x(t)$ can be expressed in the form $$x(t) = \int_\Gamma X(s) \, e^{st} ds$$ Where $X(s)$ is a particular function of a complex variable $s$ and $\Gamma$ is a particular path through the complex plane. It is not important to be able to evaluate such an integral but it is very important that it can be expressed in this form. 
\end{document}
